{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ycksYvJ4lZB"
   },
   "source": [
    "Homework 3: n-gram LM\n",
    "----\n",
    "\n",
    "Due date: October 4th, 2023\n",
    "\n",
    "Points: 105\n",
    "\n",
    "Goals:\n",
    "- understand the difficulties of counting and probablities in NLP applications\n",
    "- work with real world data to build a functioning language model\n",
    "- stress test your model (to some extent)\n",
    "\n",
    "Complete in groups of: __one (individually)__\n",
    "\n",
    "Allowed python modules:\n",
    "- `numpy`, `matplotlib`, and all built-in python libraries (e.g. `math` and `string`)\n",
    "- do not use `nltk` or `pandas`\n",
    "\n",
    "Instructions:\n",
    "- Complete outlined problems in this notebook.\n",
    "- When you have finished, __clear the kernel__ and __run__ your notebook \"fresh\" from top to bottom. Ensure that there are __no errors__.\n",
    "    - If a problem asks for you to write code that does result in an error (as in, the answer to the problem is an error), leave the code in your notebook but commented out so that running from top to bottom does not result in any errors.\n",
    "- Double check that you have completed Task 0.\n",
    "- Submit your work on Gradescope.\n",
    "- Double check that your submission on Gradescope looks like you believe it should __and__ that all partners are included (for partner work).\n",
    "\n",
    "6120 students: complete __all__ problems.\n",
    "\n",
    "4120 students: you are not required to complete problems marked \"CS 6120 REQUIRED\". If you complete these you will not get extra credit. We will not take points off if you attempt these problems and do not succeed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RPQYlmS4lZD"
   },
   "source": [
    "Task 0: Name, References, Reflection (5 points)\n",
    "---\n",
    "\n",
    "Name: Anisha Kumari Kushwaha\n",
    "\n",
    "References\n",
    "---\n",
    "List the resources you consulted to complete this homework here. Write one sentence per resource about what it provided to you. If you consulted no references to complete your assignment, write a brief sentence stating that this is the case and why it was the case for you.\n",
    "\n",
    "(Example)\n",
    "- https://docs.python.org/3/tutorial/datastructures.html\n",
    "    - Read about the the basics and syntax for data structures in python.\n",
    "    \n",
    "    \n",
    " https://towardsdatascience.com/perplexity-in-language-models-87a196019a94\n",
    " Read about Perplexity Score\n",
    " \n",
    " https://towardsdatascience.com/evaluation-of-language-models-through-perplexity-and-shannon-visualization-method-9148fbe10bd0\n",
    " Read about Perplexity Score \n",
    "    \n",
    "AI Collaboration\n",
    "---\n",
    "Following the *AI Collaboration Policy* in the syllabus, please cite any LLMs that you used here and briefly describe what you used them for. Additionally, provide comments in-line identifying the specific sections that you used LLMs on, if you used them towards the generation of any of your answers.\n",
    "\n",
    "Reflection\n",
    "----\n",
    "Answer the following questions __after__ you complete this assignment (no more than 1 sentence per question required, this section is graded on completion):\n",
    "\n",
    "1. Does this work reflect your best effort? \n",
    "\n",
    "    Yes\n",
    "\n",
    "\n",
    "2. What was/were the most challenging part(s) of the assignment? \n",
    "\n",
    "    Dealing with UNK token while scoring probabilities.\n",
    "\n",
    "\n",
    "3. If you want feedback, what function(s) or problem(s) would you like feedback on and why? \n",
    "\n",
    "    I'm unsure about Perplexity as there is no way to cross check it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocD7TgWq4lZD"
   },
   "source": [
    "Task 1: Berp Data Write-Up (5 points)\n",
    "---\n",
    "\n",
    "Every time you use a data set in an NLP application (or in any software application), you should be able to answer a set of questions about that data. Answer these now. Default to no more than 1 sentence per question needed. If more explanation is necessary, do give it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rROI3n8t4lZE"
   },
   "source": [
    "This is about the __berp__ data set.\n",
    "\n",
    "1. Where did you get the data from? https://www1.icsi.berkeley.edu/Speech/berp.html\n",
    "\n",
    "\n",
    "2. How was the data collected (where did the people acquiring the data get it from and how)?\n",
    "\n",
    "      The data was likely acquired through the recording of spontaneous continuous speech interactions with users in the domain of restaurants in the city of Berkeley, which serves as the system's knowledge domain.\n",
    "      \n",
    "\n",
    "3. How large is the dataset? (# lines, # tokens)\n",
    "\n",
    "    It contains 7500 lines, with 1500 words\n",
    "\n",
    "\n",
    "4. What is your data? (i.e. newswire, tweets, books, blogs, etc)\n",
    "\n",
    "    The data given to us is a file with sentences in each line.\n",
    "    \n",
    "\n",
    "5. Who produced the data? (who were the authors of the text? Your answer might be a specific person or a particular group of people)\n",
    "\n",
    "    It is developed by the International Computer Science Institute in Berkeley, CA, in a project headed by Nelson Morgan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JmhMgrW-4lZE"
   },
   "source": [
    "Task 2: Implement an n-gram Language Model (90 points)\n",
    "----\n",
    "\n",
    "Implement the `LanguageModel` class as outlined in the provided `lm_starter.py` file. Do not change function signatures (the unit tests that we provide and in the autograder will break).\n",
    "\n",
    "Your language model:\n",
    "- *must* work for both the unigram and bigram cases (5 points are allocated to an experiment involving larger values of `n`)\n",
    "    - 6120 students must create a model that works for trigram cases as well\n",
    "    - hint: try to implement the bigram case as a generalized \"n greater than 1\" case\n",
    "- should be *token agnostic* (this means that if we give the model text tokenized as single characters, it will function as a character language model and if we give the model text tokenized as \"words\" (or \"traditionally\"), then it will function as a language model with those tokens)\n",
    "- will use Laplace smoothing\n",
    "- will replace all tokens that occur only once with `<UNK>` at train time\n",
    "    - do not add `<UNK>` to your vocabulary if no tokens in the training data occur only once!\n",
    "\n",
    "We have provided:\n",
    "- a function to read in files\n",
    "- some functions to change a list of strings into tokens\n",
    "- the skeleton of the `LanguageModel` class\n",
    "\n",
    "You need to implement:\n",
    "- all functions marked\n",
    "\n",
    "You may implement:\n",
    "- additional functions/methods as helpful to you\n",
    "\n",
    "As a guideline, including comments, all code required for CS 6120 and some debugging code that can be run with `verbose` parameters, our solution is ~300 lines. (~+120 lines versus the starter code).\n",
    "\n",
    "Points breakdown marked in code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "N67cvpcY4lZE"
   },
   "outputs": [],
   "source": [
    "# rename your lm_starter.py file to lm_model.py and put in the same directory as this file\n",
    "import lm_model as lm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import groupby\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_HxaQy5C4lZF",
    "outputId": "310ab5de-9942-4b00-c386-d83c174c9ca9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['<s>', '</s>'], ['<s>', 'am', '</s>']]\n",
      "[['<s>', 'ham', 'i', 'am', '</s>'], ['<s>', 'ham', '</s>']]\n"
     ]
    }
   ],
   "source": [
    "# test the language model (unit tests)\n",
    "import test_minitrainingprovided as test\n",
    "\n",
    "# passing all these tests is a good indication that your model\n",
    "# is correct. They are *not a guarantee*, so make sure to look\n",
    "# at the tests and the cases that they cover. (we'll be testing\n",
    "# your model against all of the testing data in addition).\n",
    "\n",
    "# autograder points in gradescope are assigned SIXTY points\n",
    "# this is essentially 60 points for correctly implementing your\n",
    "# underlying model\n",
    "# there are an additional 10 points manually graded for the correctness\n",
    "# parts of your sentence generation\n",
    "\n",
    "# make sure all training files are in a \"training_files\" directory\n",
    "# that is in the same directory as this notebook\n",
    "\n",
    "unittest = test.TestMiniTraining()\n",
    "unittest.test_createunigrammodellaplace()\n",
    "unittest.test_createbigrammodellaplace()\n",
    "unittest.test_unigramlaplace()\n",
    "unittest.test_unigramunknownslaplace()\n",
    "unittest.test_bigramlaplace()\n",
    "unittest.test_bigramunknownslaplace()\n",
    "# produces output\n",
    "unittest.test_generateunigramconcludes()\n",
    "# produces output\n",
    "unittest.test_generatebigramconcludes()\n",
    "\n",
    "unittest.test_onlyunknownsgenerationandscoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XjGf9sqt4lZF",
    "outputId": "9f7bad3a-c42b-4922-cddc-60cd3acbd9a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 10 sentences are: \n",
      "\n",
      "1 not cost less\n",
      "2 let's let's start over\n",
      "3 lots of any type of the maharani serve <UNK> restaurant\n",
      "4 what's the <UNK> and uh with mediterranean food for ten dollars\n",
      "5 i want\n",
      "6 it got a little more than five dollars\n",
      "7 can i want to the closest to go in berkeley thai restaurants open\n",
      "8 oh i'd like to see one hour\n",
      "9 are available uh let's start over\n",
      "10 i would like to icksee\n"
     ]
    }
   ],
   "source": [
    "# 5 points\n",
    "\n",
    "# instantiate a bigram language model, train it, and generate ten sentences\n",
    "# make sure your output is nicely formatted!\n",
    "ngram = 2\n",
    "training_file_path = \"training_files/berp-training.txt\"\n",
    "# optional parameter tells the tokenize function how to tokenize\n",
    "by_char = False\n",
    "data = lm.read_file(training_file_path)\n",
    "tokens = lm.tokenize(data, ngram, by_char=by_char)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "lmc = lm.LanguageModel(ngram)\n",
    "lmc.train(tokens)\n",
    "\n",
    "lines = lmc.generate(10)\n",
    "\n",
    "print(\"Generated 10 sentences are: \\n\")\n",
    "for i in range(len(lines)):\n",
    "  print(i+1, ' '.join(lines[i][1:-1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OP_KlyAF4lZG",
    "outputId": "b7390b0c-e202-4435-f317-7012b883e3cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score:  4.9620823627262653e-05\n",
      "Standard Deviation :  0.000285298086084196\n"
     ]
    }
   ],
   "source": [
    "# 5 points\n",
    "\n",
    "# evaluate your bigram model on the test data\n",
    "# score each line in the test data individually, then calculate the average score\n",
    "# you need not re-train your model\n",
    "test_path = \"testing_files/berp-test.txt\"\n",
    "test_data = lm.read_file(test_path)\n",
    "\n",
    "scores = []\n",
    "\n",
    "# YOUR CODE HERE\n",
    "scores = [lmc.score(lm.tokenize_line(line, ngram, by_char)) for line in test_data ]\n",
    "# print(\"Inidividual Score: \",scores)\n",
    "print(\"Average Score: \", np.average(scores))\n",
    "print(\"Standard Deviation : \",np.std(scores))\n",
    "\n",
    "# scores = [lmc.score(' '.join(line)) for line in each_line]\n",
    "# print(scores)\n",
    "# average_score = average = sum(scores) / len(scores)\n",
    "# print(average_score)\n",
    "# Print out the mean score and standard deviation\n",
    "# for words-as-tokens, these values should be\n",
    "# ~4.9 * 10^-5 and 0.000285\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hFSyr6qH4lZG",
    "outputId": "f31b55b5-f075-45c4-e23e-9db416eaab5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 3 sentences: \n",
      "\n",
      "1 that she would be\n",
      "2 Avenue. It hadn't been <UNK> <UNK> von <UNK>\n",
      "3 take advantage of \"Fire!\" <UNK> what of a doubt that <UNK> out his <UNK> He was still this question <UNK> me in. She was at the lamps had rushed at <UNK>\n"
     ]
    }
   ],
   "source": [
    "# 5 points\n",
    "\n",
    "# see if you can train your model on the data you found for your first homework\n",
    "ngram = 10\n",
    "dataFile = \"HW1text.txt\"\n",
    "by_char = False\n",
    "data = lm.read_file(dataFile)\n",
    "tokens = lm.tokenize(data, ngram, by_char=by_char)\n",
    "# print(\"tokens:\", tokens)\n",
    "lmc = lm.LanguageModel(ngram)\n",
    "lmc.train(tokens)\n",
    "\n",
    "# what is the maximum value of n <= 10 that you can train a model *in your programming environment* in a reasonable amount of time? (less than 3 - 5 minutes)\n",
    "\n",
    "\n",
    "# generate three sentences with this model\n",
    "lines = lmc.generate(3)\n",
    "print(\"Generated 3 sentences: \\n\")\n",
    "for i in range(len(lines)):\n",
    "  print(i+1, ' '.join(lines[i][1:-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiuuhkWR4lZG"
   },
   "source": [
    "CS 6120 REQUIRED\n",
    "----\n",
    "Implement the corresponding function and evaluate the perplexity of your model on the first 20 lines in the test data for values of `n` from 1 to 3. Perplexity should be individually calculated for each line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y8lNbCf94lZG",
    "outputId": "5c50fc56-04bc-4714-ea0e-ed2fca2455df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********\n",
      "Ngram model: 1\n",
      "\n",
      "Line 1  :  a vegetarian meal\n",
      "\n",
      "    Perplexity: 13.909097001971821\n",
      "\n",
      "Line 2  :  about ten miles\n",
      "\n",
      "    Perplexity: 9.756733216337008\n",
      "\n",
      "Line 3  :  and i'm willing to drive ten miles\n",
      "\n",
      "    Perplexity: 10.195553650348451\n",
      "\n",
      "Line 4  :  and this will be for dinner\n",
      "\n",
      "    Perplexity: 9.818395235754153\n",
      "\n",
      "Line 5  :  are any of these restaurants open for breakfast\n",
      "\n",
      "    Perplexity: 10.23979910708653\n",
      "\n",
      "Line 6  :  are there russian restaurants in berkeley\n",
      "\n",
      "    Perplexity: 10.280828998956883\n",
      "\n",
      "Line 7  :  between fifteen and twenty dollars\n",
      "\n",
      "    Perplexity: 9.155844704408999\n",
      "\n",
      "Line 8  :  can you at least list the nationality of these restaurants\n",
      "\n",
      "    Perplexity: 10.89893425587025\n",
      "\n",
      "Line 9  :  can you give me more information on viva taqueria \n",
      "\n",
      "    Perplexity: 11.166839008684798\n",
      "\n",
      "Line 10  :  dining\n",
      "\n",
      "    Perplexity: 11.854739896051703\n",
      "\n",
      "Line 11  :  display sizzler\n",
      "\n",
      "    Perplexity: 10.724109042023283\n",
      "\n",
      "Line 12  :  do you have indonesian food \n",
      "\n",
      "    Perplexity: 9.999309436034542\n",
      "\n",
      "Line 13  :  do you know any pizza places\n",
      "\n",
      "    Perplexity: 10.26949401527957\n",
      "\n",
      "Line 14  :  doesn't matter\n",
      "\n",
      "    Perplexity: 8.961565676905103\n",
      "\n",
      "Line 15  :  eat on a weekday\n",
      "\n",
      "    Perplexity: 11.51824543757834\n",
      "\n",
      "Line 16  :  eight dollars\n",
      "\n",
      "    Perplexity: 10.093297761897313\n",
      "\n",
      "Line 17  :  expensive\n",
      "\n",
      "    Perplexity: 8.951477144798496\n",
      "\n",
      "Line 18  :  five miles\n",
      "\n",
      "    Perplexity: 10.130754222704779\n",
      "\n",
      "Line 19  :  give me the list of restaurants in berkeley \n",
      "\n",
      "    Perplexity: 9.42145082485463\n",
      "\n",
      "Line 20  :  how about italian and quite expensive is fine\n",
      "\n",
      "    Perplexity: 11.434294791432967\n",
      "********\n",
      "Ngram model: 2\n",
      "\n",
      "Line 1  :  a vegetarian meal\n",
      "\n",
      "    Perplexity: 17.317387268384756\n",
      "\n",
      "Line 2  :  about ten miles\n",
      "\n",
      "    Perplexity: 11.526004430476217\n",
      "\n",
      "Line 3  :  and i'm willing to drive ten miles\n",
      "\n",
      "    Perplexity: 15.749013696494801\n",
      "\n",
      "Line 4  :  and this will be for dinner\n",
      "\n",
      "    Perplexity: 13.918138293790468\n",
      "\n",
      "Line 5  :  are any of these restaurants open for breakfast\n",
      "\n",
      "    Perplexity: 13.801943772017879\n",
      "\n",
      "Line 6  :  are there russian restaurants in berkeley\n",
      "\n",
      "    Perplexity: 14.163159763272718\n",
      "\n",
      "Line 7  :  between fifteen and twenty dollars\n",
      "\n",
      "    Perplexity: 12.839366665504054\n",
      "\n",
      "Line 8  :  can you at least list the nationality of these restaurants\n",
      "\n",
      "    Perplexity: 16.804671320955553\n",
      "\n",
      "Line 9  :  can you give me more information on viva taqueria \n",
      "\n",
      "    Perplexity: 17.881046190481246\n",
      "\n",
      "Line 10  :  dining\n",
      "\n",
      "    Perplexity: 18.399440222512453\n",
      "\n",
      "Line 11  :  display sizzler\n",
      "\n",
      "    Perplexity: 16.183073906665506\n",
      "\n",
      "Line 12  :  do you have indonesian food \n",
      "\n",
      "    Perplexity: 14.336719514958263\n",
      "\n",
      "Line 13  :  do you know any pizza places\n",
      "\n",
      "    Perplexity: 14.68683902780696\n",
      "\n",
      "Line 14  :  doesn't matter\n",
      "\n",
      "    Perplexity: 11.03428020589637\n",
      "\n",
      "Line 15  :  eat on a weekday\n",
      "\n",
      "    Perplexity: 15.309706210699357\n",
      "\n",
      "Line 16  :  eight dollars\n",
      "\n",
      "    Perplexity: 13.776905171063879\n",
      "\n",
      "Line 17  :  expensive\n",
      "\n",
      "    Perplexity: 11.49898606476117\n",
      "\n",
      "Line 18  :  five miles\n",
      "\n",
      "    Perplexity: 15.114985761150011\n",
      "\n",
      "Line 19  :  give me the list of restaurants in berkeley \n",
      "\n",
      "    Perplexity: 14.1416553707232\n",
      "\n",
      "Line 20  :  how about italian and quite expensive is fine\n",
      "\n",
      "    Perplexity: 19.014089475762045\n",
      "********\n",
      "Ngram model: 3\n",
      "\n",
      "Line 1  :  a vegetarian meal\n",
      "\n",
      "    Perplexity: 51.931215220050206\n",
      "\n",
      "Line 2  :  about ten miles\n",
      "\n",
      "    Perplexity: 38.745243630594025\n",
      "\n",
      "Line 3  :  and i'm willing to drive ten miles\n",
      "\n",
      "    Perplexity: 68.71520055121304\n",
      "\n",
      "Line 4  :  and this will be for dinner\n",
      "\n",
      "    Perplexity: 56.17498384941369\n",
      "\n",
      "Line 5  :  are any of these restaurants open for breakfast\n",
      "\n",
      "    Perplexity: 52.42234158575231\n",
      "\n",
      "Line 6  :  are there russian restaurants in berkeley\n",
      "\n",
      "    Perplexity: 54.18027975875836\n",
      "\n",
      "Line 7  :  between fifteen and twenty dollars\n",
      "\n",
      "    Perplexity: 48.05553955123102\n",
      "\n",
      "Line 8  :  can you at least list the nationality of these restaurants\n",
      "\n",
      "    Perplexity: 64.7711172831528\n",
      "\n",
      "Line 9  :  can you give me more information on viva taqueria \n",
      "\n",
      "    Perplexity: 68.27883477225085\n",
      "\n",
      "Line 10  :  dining\n",
      "\n",
      "    Perplexity: 29.650760286392135\n",
      "\n",
      "Line 11  :  display sizzler\n",
      "\n",
      "    Perplexity: 51.592446242903065\n",
      "\n",
      "Line 12  :  do you have indonesian food \n",
      "\n",
      "    Perplexity: 51.79116637334953\n",
      "\n",
      "Line 13  :  do you know any pizza places\n",
      "\n",
      "    Perplexity: 53.66038780307242\n",
      "\n",
      "Line 14  :  doesn't matter\n",
      "\n",
      "    Perplexity: 32.65866863345987\n",
      "\n",
      "Line 15  :  eat on a weekday\n",
      "\n",
      "    Perplexity: 42.912129278152335\n",
      "\n",
      "Line 16  :  eight dollars\n",
      "\n",
      "    Perplexity: 38.68994620226944\n",
      "\n",
      "Line 17  :  expensive\n",
      "\n",
      "    Perplexity: 32.31676830686899\n",
      "\n",
      "Line 18  :  five miles\n",
      "\n",
      "    Perplexity: 42.54292574906123\n",
      "\n",
      "Line 19  :  give me the list of restaurants in berkeley \n",
      "\n",
      "    Perplexity: 55.32463314072024\n",
      "\n",
      "Line 20  :  how about italian and quite expensive is fine\n",
      "\n",
      "    Perplexity: 76.43660251431855\n"
     ]
    }
   ],
   "source": [
    "test_path = \"training_files/berp-test.txt\"\n",
    "test_data = lm.read_file(test_path)\n",
    "\n",
    "for ngram in range(1, 4):\n",
    "    print(\"********\")\n",
    "    print(\"Ngram model:\", ngram)\n",
    "    # YOUR CODE HERE\n",
    "    data = lm.read_file(\"testing_files/berp-test.txt\")\n",
    "    tokens = lm.tokenize(data, ngram, by_char=by_char)\n",
    "    lmc = lm.LanguageModel(ngram)\n",
    "    lmc.train(tokens)\n",
    "\n",
    "    for i in range(20):\n",
    "        print(\"\\nLine\",i+1,\" : \",test_data[i] )\n",
    "        print(\"    Perplexity:\", lmc.perplexity(test_data[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TBQBT7gE4lZG"
   },
   "source": [
    "1. What are the common attributes of the test sentences that cause very high perplexity?\n",
    "\n",
    "    The lines with high ngram value has high Perplexity compared to low ngram value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mqw1613i4lZG"
   },
   "source": [
    "5 points in this assignment are reserved for overall style (both for writing and for code submitted). All work submitted should be clear, easily interpretable, and checked for spelling, etc. (Re-read what you write and make sure it makes sense). Course staff are always happy to give grammatical help (but we won't pre-grade the content of your answers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGj2ohnD4lZG"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
